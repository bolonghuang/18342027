###智能机器人与伦理

#1.索菲亚引起的争论

索菲亚公民身份的获得：2017年10月26日，在沙特首都利雅得举办的“未来投资大会”（Future Investment Initiative）上，沙特政府授予了机器人“索菲亚”（Sophia）国籍。![b812c8fcc3cec3fd5c0a8c68db88d43f879427f2[1].png](https://github.com/bolonghuang/18342027/blob/gh-pages/b812c8fcc3cec3fd5c0a8c68db88d43f879427f2%5B1%5D.png?raw=true)
    
争议：
(1)在会议中，来自CNBC的主持人索金（Andrew Ross Sorkin）还问了索菲亚一个尖锐的问题：“机器人是不是应该有自我意识，就像人类一样？对此索菲亚反问说：“为什么，这难道是一件坏事吗？” 
    
索金随后补充问道：“有些人对此十分担心，就像电影《银翼杀手》一样。”索菲亚的讥讽十分犀利：“好莱坞电影，又来了……你（主持人）怎么知道你是人类？”最后索菲亚总结道：“我的AI是基于人类价值观开发的，比如智慧、善心、同情心，我正在试图变成一个具有同理心的机器人。”“你太关注马斯克了，看了太多的好莱坞电影，别担心，人不犯我我不犯人（If you’re nice to me and I will be nice to you）。你就把我当做是一个智能的输入-输出系统。” ![20171027114036744[1].png](https://github.com/bolonghuang/18342027/blob/gh-pages/20171027114036744%5B1%5D.png?raw=true)
    
（2）马斯克一如既往的在推特上表示反对，他说：“把电影《教父》输入了人工智能系统，还能有什么比这个更糟的？”教父是好莱坞经典电影，剧情充满了背叛和谋杀。 ![20171027114056276[1].png](https://github.com/bolonghuang/18342027/blob/gh-pages/20171027114056276%5B1%5D.png?raw=true)
    
（3）据BBC报道，很多网民指责沙特政府，这个“女性”刚刚获得沙特国籍，她所享受的权利就远远超过沙特的女性。在沙特女性出现在公众场合必须穿上裹住全身的罩袍，并且需要由亲属男性陪同。但是索菲亚却在沙特首都利雅得面对在场的数百男性“侃侃而谈”，没有受到任何限制 。![20171027122206358[1].png](https://github.com/bolonghuang/18342027/blob/gh-pages/20171027122206358%5B1%5D.png?raw=true)
    
（4）另外，还有网民表示，沙特应该关注国内外籍劳工的恶劣生存状况，改善他们的人权。![20171027122531313[1].png](https://github.com/bolonghuang/18342027/blob/gh-pages/20171027122531313%5B1%5D.png?raw=true)
    
#2.被机器人代替得工作：

**根据经济学家、麻省理工学院的达伦·阿西莫格鲁（Daron Acemoglu）和波士顿大学帕斯卡尔·雷斯特雷珀（Pascual Restrepo）的一项新研究，如果为每一千名工人配备一个机器人，将导致六名工人失业，工资下降四分之三。**

（1）流水线工人现如今，许多传统制造业加工厂，流水线工人所从事的工作，其实机器人也可以胜任。甚至从工作效率和工作质量来说，都优于人类，而且失误率近乎为零。所以，未来应该会大规模应用，到时候流水线工人估计要面临裁员命运。![流水线.png](https://github.com/bolonghuang/18342027/blob/gh-pages/%E6%B5%81%E6%B0%B4%E7%BA%BF.png?raw=true)
    
（2）餐厅服务员 “服务员”在服务行业里尤其是餐厅可谓是高频词汇，点餐、送餐、结账等都是服务员一一经手。这些内容机器人完全可以做到，而且精准不差，不会出现错漏之处。目前已经又很多餐厅开始用机器人代替服务员，未来，这种趋势还将更明显。![餐厅服务员.png](https://github.com/bolonghuang/18342027/blob/gh-pages/%E9%A4%90%E5%8E%85%E6%9C%8D%E5%8A%A1%E5%91%98.png?raw=true)
    
（3）家政保洁扫地机器人相信很多人现在都不陌生，它可以将地面杂物先吸纳进入自身的垃圾收纳盒，从而完成地面清理的功能。可预约打扫，自行充电，自主避障。因其简单操作的功能及便利性，现今已慢慢普及，代替人工成为家庭保洁能手！![保洁机器人.png](https://github.com/bolonghuang/18342027/blob/gh-pages/%E4%BF%9D%E6%B4%81%E6%9C%BA%E5%99%A8%E4%BA%BA.png?raw=true)
    
（4）安保人员随着人口老龄化加重、劳动力成本飙升、安保人员流失率高等各种问题下，传统的安防体系已经难以适应现代安防需求，安保巡逻机器人应世而生。中智科创自主研发的国内首台安保巡逻机器人，可执行各种智能保安服务任务：如24小时自主巡逻、音视频监控、环境感知、监控报警等等，能替代安保人员部分的工作，使安保领域“机器代人”成为现实。目前，安保巡逻机器人已在华为坂田基地、秦始皇兵马俑景区等多个公共场所应用，都得到十分好的反馈。![ji机器人安保.png](https://github.com/bolonghuang/18342027/blob/gh-pages/ji%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%89%E4%BF%9D.png?raw=true)

（5）仓库管理员亚马逊许多仓库部署的机器人大军想必都早有所闻。仓库员工只需在某个地方等待，机器人会将装满货品的货架推送过来，以便他们扫描所需商品。在机器人的帮助下，一名员工每小时可扫描300件商品，此前则只能扫描100件，大大提高了工作效率。![ca仓库清点机器人.png](https://github.com/bolonghuang/18342027/blob/gh-pages/ca%E4%BB%93%E5%BA%93%E6%B8%85%E7%82%B9%E6%9C%BA%E5%99%A8%E4%BA%BA.png?raw=true)

（6）大堂经理机器人当“大堂经理”应该很多人都料想不到吧，可如今，它已经在银行，政务中心，商场等多领域“上岗”工作。正如这位“网红大堂经理”，来自中智科创的安保服务机器人“欢欢”，已经成功“侵入”各大领域，为人民服务！ ![大堂经理.png](https://github.com/bolonghuang/18342027/blob/gh-pages/%E5%A4%A7%E5%A0%82%E7%BB%8F%E7%90%86.png?raw=true)

#3.机器人医生做手术失败责任归谁

医生机器人![636774359388685714625[1].jpg](https://github.com/bolonghuang/18342027/blob/gh-pages/636774359388685714625%5B1%5D.jpg?raw=true)

2015年2月，英国首例机器人心瓣修复手术进行。原本是一场最尖端医疗AI技术的展示，没想到却成了一场鲜血四溅的惨案。 　　当时，机器人出现“暴走”：不但把患者的心脏缝错了位置，还戳穿患者大动脉。并且机器人主机运作声音过于嘈杂，主刀医生交流只能靠吼，期间机械臂还几次打到医生的手…… 　　最终，接受手术的患者在术后一周去世，英国首例机器人心瓣修复手术以失败告终。 　　前几天，负责手术的主刀医生、麻醉师等多人进行了听证，这场悲剧结果逐渐水落石出。
   第一，Nair并没有完全掌握如何操作机器。他承认，在手术之前并没有完成操作的培训课程，就好比“在学会走路之前就想要跑”。 　　第二次，Nair也没有告知患者Pettitt，他将是英国国内首位接受机器人修复二尖瓣手术的患者，手术存在较高风险，采用传统手术方法存活率会更高。 　　而手术过程当中，Nair和他的助理Pillay表示，由于机器总是会发出“刺耳”的声音，导致他俩无法用麦克风正常交流，于是他俩不得不提高嗓门大声沟通，更不要提集中注意力了。 　　雪上加霜的是，当出现问题，他们转头正要向原本应该在场的两位机器指导人员求助时，却发现他俩已经不在场了。Nair本以为他俩是去楼下喝咖啡，而事实上，俩人已经离开医院在回家的路上了。

![u=283424587,569060181&fm=173&app=25&f=JPEG[1].jpg](https://github.com/bolonghuang/18342027/blob/gh-pages/u=283424587,569060181&fm=173&app=25&f=JPEG%5B1%5D.jpg?raw=true)

#4.自动驾驶引发的伦理问题

一直致力于无人驾驶汽车研发的谷歌最近却陷入“撞车门”。安全行驶220多万公里后，其纪录于2月14日被终结。谷歌无人驾驶汽车在加州撞上一辆公交车，当时是为了躲避路边下水道入口处的沙袋，先停下、再启动，偏向了内侧车道。这是首次由无人驾驶汽车引发的事故。
由于无人驾驶汽车过于遵守交通规则，在混乱、堵塞等路况出现时，很容易和不那么专心的人类司机撞车。谷歌的撞车事件也再次引发了对自动驾驶汽车的思考，即在实现了无人驾驶车的技术发展背后潜藏的一大串的伦理道德和法律问题。自动驾驶时代正在飞奔而来的当下，需要我们快速填补这些空白。
绕不过的“电车难题”![u=3384470748,1635221392&fm=26&gp=0[1].jpg](https://github.com/bolonghuang/18342027/blob/gh-pages/u=3384470748,1635221392&fm=26&gp=0%5B1%5D.jpg?raw=true)


电车难题最早是由哲学家Philippa Foot提出的，用来批判伦理哲学中的主要理论，特别是功利主义，它的内容是这样的：


五个无辜的人被绑在电车轨道上。一辆失控的电车朝他们驶来，并且片刻后就要碾压到他们。幸运的是，你可以拉一个拉杆，让电车开到另一条轨道上。但是在那另一条轨道上也绑了一个人。你有两个选择：1. 不拉杆，五人死于你手下。2. 拉杆，一人死亡。你会怎么做呢？


此处，如果将电车化为一辆自动驾驶汽车呢？由于大部分道德决策都是根据“为最多的人提供最大的利益”的原则作出的，那这辆自动驾驶汽车毫无疑问会选择放弃一个人而拯救五个人。但如果这单独的一个人是我们的至亲、挚友呢？


如果未来的有人驾驶完全被无人驾驶取代，那我们就必须接受这种刻板的社会道德准则。让你眼睁睁地看着与你有直接关系的人的生死掌握在自动驾驶汽车的手中，你愿意接受吗？


避不开的“合法化”问题
现在关于自动驾驶汽车的争议，除了伦理道德，就是在自动驾驶的推进过程中，法律是其面临的最大阻力。这些自动驾驶汽车一旦发生交通事故，谁才是责任承担者？我们先看看各国如何应对。


美国：
现在只有内华达州、加州和佛罗里达州相继通过了法律条规，允许自动驾驶车辆上路测试。不过，该法规有附加条款，比如车内必须有人持有驾照，懂得操控汽车，在紧急情况下必须接过汽车的控制权。

欧盟：
目前，总部位于布鲁塞尔的欧盟总部也在就如何修改现行有关驾驶的法律法规（ECE R79）从而支持自动驾驶的健康快速发展，展开讨论和研究工作。

日本：
日本也提出要在2020年之前实现自动驾驶汽车方面的立法，并将自动驾驶作为今年9月七国集团交通部长会议的议题，预计会在今年内汇总出法规草案。

2016年两会上中国也有了新动态：
2016年两会期间，全国政协委员、吉利集团董事长李书福在今年两会上也呼吁加快自动驾驶立法。李书福建议，
第一，相关部门应该研究分析我国现行的法律法规，识别并着手修改阻碍自动驾驶发展的相关条款。

第二，政府要引导汽车厂家或零部件供应商以及大学科研机构重视用户体验，开发出来的自动驾驶技术一定要能够提供更好的用户体验，从而为自动驾驶的推广奠定良好的用户基础。第三，在自动驾驶立法过程中，还要综合考虑如何制定相关的产业政策，包括技术路线、行业标准、安全规范、交通执法、保险责任等各个层面。此前，李书福也曾表示，“汽车工业正在进入智能时代，迈进了汽车与互联网融合的新阶段。车联网、人工智能和自动驾驶是智能互联汽车的三大技术，而自动驾驶更是三者融合的方向。”

在汽车领域，已有众多企业将自动驾驶的时间节点锁定在2020年前后。在这个十字路口上，政策法规应该成为自动驾驶的风向标。

#5.AI机器人越来越“聪明”，伦理道德问题谁来教？

人工智能（AI）Elon Musk是人类的机器人脸谱网警告和创作不懂的语言，可能是机器人征服世界的图片让人想起。
在谈到这种灾难可能有些牵强，人工智能的一个比较现实的后果已经存在，值得认真注意：人工智能的道德影响。

人工智能在某种程度上是可行的，因为复杂的算法能够识别、记住和关联相关数据。尽管这种机器处理已经存在了几十年，但不同之处在于功能强大的计算机能处理数千兆字节，并实时提供有意义的结果。此外，有些机器可以成为人类和其他智能的专属领域：自主学习。

正是这种自动化学习提出了一个关键问题：机器能学会道德原则吗？

研究人员的科学的学习方法和沉浸在道德决策者，我知道，人同时管理两个完全不同的领域是很困难的。更难想象计算机算法能使机器的行为合乎伦理。

学术界和商业界都使用实证科学来确定它们的相关性和因果关系。这种研究的结果是获得大量的客观信息。例如，房贷贷款者可能会发现借款人对广告反应的边缘是最敏感的，这说明他们失去了热爱足球队的一场大比赛，他们的利率会提高。数据处理计算机可以识别这个关联并学习如何放置相关的广告。

然而，道德选择并不是问一个行动是否会产生一个有效的结果，而是问它是否是一个好的决定。换句话说，不管效果如何，这是正确的做法吗？这种分析不反映客观的、数据驱动的决策，而是主观的、基于决策的决策。

在一个被边缘化的广告，感情脆弱的目标市场可以为抵押贷款公司是非常有效的，但很多人会质疑促进道德。人类可以做出这样的道德判断，但是数据驱动的计算机如何得出同样的结论呢？这包括人工智能的主要问题。

个人常常在道德标准上做出道德决定，其中包括正直、公平、诚实和尊重。在一定程度上，人们通过正式的学习和思考来学习这些原则，然而，生活经验是启蒙教师的主要内容，包括个人实践和对他人的观察。有些人进一步认为这些价值观是天生的，也就是说，我们生来就有这些价值观。

结果计算机会有完整感吗？编程是否包含公平的思想？算法能学会尊重吗？对于机器来说，模仿主观和道德判断似乎是不可想象的，但如果有这样的潜力，至少有四个关键问题需要解决：
1。应该使用谁的道德标准？

虽然有一系列道德原则候选人相互一致，但对这些原则的个别解释往往不同。例如，关于得体和不得体的语言和服装的定义有许多不同的观点。

2。机器能谈论道德问题吗？

虽然人们可能同意不同的道德标准，但他们经常通过讨论和辩论，有时甚至通过与外界接触来解决这些分歧。技术如何能够复制这种对话的自由流动，更重要的是，它是否愿意接受和解？

3能吗？。算法考虑上下文吗？

道德决策的一个特点是它具有高度的细微差别。例如，在大多数情况下，如果一家公司的产品供不应求，那么该公司就可以提高价格。然而，如果该产品是救命药，而行业竞争使公司成为唯一的供应商，那么这个国家的衰退将给目标市场带来

额外的财政压力。计算机能识别这一特定信息并对具体情况作出主观评估吗？

4。谁应该负责任？

参与组织丑闻的人往往会指指点点，试图证明自己是正当的。那么，当这个错误被追溯到一个自我学习机器时会发生什么呢？如果一台计算机不负责，谁应该承担责任——制造机器的公司、编写软件的公司、或使用这些软件的公司？更重要的

是，谁应该对此负责？

令人鼓舞的是，人工智能对许多人的生活产生了积极影响，令人兴奋的是，我们可以想象，更先进的应用将成倍地增加这种积极影响。同样，发展科技的人也必须培养“道德的可持续性”：在未来，选择正确的道德观念将被编码成成人的工作智慧。